---
title: "Rapport - Séries Temporelles"
btitle: "A demonstration of Rmarkdown using Herman Bumpus' data"
author: "Philippe Real"
date: '`r format(Sys.time(), " %d %B, %Y")`'
abstract: "This is my abstract."
keywords: "Time series, ARIMA"
output:
  pdf_document:
    toc: yes
    toc_depth: 3
    fig_caption: yes
    keep_tex: yes
    number_sections: true
  word_document:
    toc: yes
  html_document:
    df_print: paged
    toc: yes
---


```{r eval=FALSE, message=FALSE, warning=FALSE, include=FALSE}

#for manipulate data (transform to dataframe)
install.packages("tidyverse")
install.packages("tibble")
install.packages("sm")
install.packages("KernSmooth")
install.packages("np")
install.packages("stats")
install.packages("ggplot2")
install.packages("kedd")
install.packages("caschrono")
install.packages("brms")
#install.packages("its") à installer manuellement
install.packages("forecast")
install.packages("TSA")
#install.packages("aTSA")
install.packages("tseries")
install.packages("TTR")
install.packages("gridExtra")
install.packages("nortest")
```

```{r r_utile, message=FALSE, warning=FALSE, include=FALSE}
## Load libraries 
#rm(list=ls())

#chargement des librairies utilses
library(tibble)
library(ggplot2)
library(KernSmooth)
library(stats)
library(np)
library(kedd)
library(tidyverse)
library(caschrono)
library(brms)
#library(its)
library(forecast)
library(TSA)
#library(aTSA)
library(tseries)
library(TTR)
library(gridExtra)
require(graphics)
library(nortest)
# Introduction
```


\pagebreak

# Partie I - Exemple de modélisation appliqué au traffic voyageur

## Lecture des données et premières analyses de la série temporelle

### Lecture des données

```{r echo=FALSE}
sncf=read.table("http://freakonometrics.free.fr/sncf.csv",header=TRUE,sep=";")
train=as.vector(t(as.matrix(sncf[,2:13])))
Traffic_SNCF=ts(train,start = c(1963, 1), frequency = 12)
```

```{r echo=FALSE}
head(Traffic_SNCF,24)
```

```{r echo=FALSE}
summary(Traffic_SNCF)
```

### Chronogramme de la séries temporelles - sncf

On a 4 séries temporelles possibles en fonction du choix de la quantité observée (High, Low, Open, Close, Volume).
On va s'intéresser à la valeur à la fermeture pour la cotation de l'indice CAC40 (Close).

```{r echo=FALSE}
#par(mfrow=c(2,2))
plot(Traffic_SNCF, xlab="Années",ylab="Nombre de voyageurs",main="Traffic sncf - 1963 à 1980",col='darkgreen',lwd=1)
```


### Représentations graphiques : month-plot et lag-plot

Si le diagramme retardée suggére une corrélation entre les deux séries, on dit que la série présente une autocorrélation d'ordre k.Ce diagramme permet de comprendre la dépendance de la série par rapport à son passée. Il donne une vision locale de la série, si y a une corrélation entre la série a un instant et la série 1, 2... instants avant.

```{r echo=FALSE, fig.height=4, fig.width=7}
monthplot(Traffic_SNCF)
```

Les tracés du chronogramme et du diagramme par mois montrent un motif saisonnier global avec une tendance à l'augmentation du nombre du traffic en juillet août ainsi que décembre.

```{r echo=FALSE, fig.height=4, fig.width=7}
lag.plot(Traffic_SNCF,lags=12,layout=c(3,4),do.lines=FALSE)
```

Le lag plot indique une saisonnalité de 1 an (période T=12 mois) marquée.

### Tendance et saisonnalité

On cherche ici à analyser la série et à déterminer une tendance (allure moyenne) aisni qu'un comportement périodique ou saisonnalité aisni que des variations exeptionnelles, qu'il faut alors expliquer.

* Estimation de la tendance par moindre carré ordinaire

On suppose que la série est de la forme $X_t = m_t + z_t$ avec $m_t = \beta^*_0 + \beta_1^*t$ et $z_t$ l'ereur ou résidus.
On cherche à estimer par l'estimateur des moindres carrés, les paramètres $\beta_0^*$ et $\beta_1^*$ à partir de la série des observations.

La tendance obtenu est une droite, la droite de régression par mco.
```{r echo=FALSE}
lm1 <- lm(Traffic_SNCF~time(Traffic_SNCF))
#lm1
#summary(lm1)
```
```{r echo=FALSE, fig.height=6, fig.width=15}
par(mfrow=c(1,2))
plot(Traffic_SNCF ,xlab='Année',ylab='Traffic voyageurs', main="Tendance obtenue par mco")
abline(lm1,col=2)
plot(as.vector(time(Traffic_SNCF)),lm1$residuals,xlab='Année',ylab='Résidu du modèle', main="Résidus du modèle mco",pch=1)
```

* Estimation de la tendance par moyennes mobiles

On cherche ici à ajuster un modèle à la courbe observée et parmis les nombreuses méthodes statistiques disponibles (ondelettes, noyaux, splines...) on va utiliser la méthode des moyennes mobiles qui est bien adaptée aux série temporelles.
Pour celà on utilise la fonction "ma" du package "forcast" de R.  
On a remarqué une saisonnalité de 12 mois (1 an) on efffectue ici une moyenne mobile d'ordre 12 pour obtenir la tendance (ma avec le paramètre order=12). 

```{r echo=FALSE, fig.height=5, fig.width=14}
require(forecast)
trend_sncf=ma(Traffic_SNCF,order=12,centre = T)
par(mfrow=c(1,2))
#plot(as.ts(trend_sncf),ylim=c(1500,4000),col="red")
plot(Traffic_SNCF,xlab='Année', main="Tendance obtenue par ma - order=12")
points(trend_sncf,col="red",type='l')
plot(Traffic_SNCF-trend_sncf,xlab="Année",pch=1,type="p", main="Résidus du modèle ma-order=12")

```
L'ajustement à l'évolution globale de la courbe est meilleur mais les résidus ont peu évolués et toujours aussi peu centrés en 0.

\pagebreak

* Série décomposée - Tendance, Saisonnalité, Résidus  

Avant d'établir les différentes coposantes de la série, on va déterminer la catégorie du modèle : additif ou multiplicatif.
Pour savoir quel modèle est le plus adapté entre additif et multiplicatif on peut utiliser la méthode de la bande ou du profil.
Dans la méthode de la bande on regarde si les 2 droites sont à peu près parrallèles et dans la méthode du profil si les c'est le cas pour les différentes courbes on conclut alors à un modèle est additif. Et multiplicatif dans le cas contraire. 
```{r echo=FALSE, fig.height=5, fig.width=14}
par(mfrow=c(1,2))
MatX=matrix(data=Traffic_SNCF,nrow=12)
Min=apply(MatX,2,min)
Max=apply(MatX,2,max)
AnneeMin=c(1964:1981)
AnneeMax=c(1963:1980)
plot.ts(Traffic_SNCF, main="Méthode de la bande")
points(AnneeMin,Min,col="blue",type = "l")
points(AnneeMax,Max,col="red",type = "l")

MatX=matrix(data=co2,nrow=12)
plot(c(1:12),MatX[,1],"l",xlim=c(1,12),ylim=c(310,330),xlab="Mois", ylab="par année", main="Méthode du profil")
 for(i in 2:12)
 {
lines(as.ts(MatX[,i]),col=i)
}
```
Dans notre cas la méthode de la bande indiquerait un modèle additif à partir de l'année 1968. La méthode du profil plaide aussi plutôt pour un modèle additif. 

On va donc utiliser un modèle additif, c'est à dire que l'on va décomposer la série sous la forme $X_t = m_t + s_t + z_t$ avec 
$m_t$ : La tendance (orientation à long terme), $s_t$ : La saisonnalité (phénomène, composante périodique ou saisonnière) et $z_t$ : L'erreur ou résidu, dont la variation doit être faible par rapport aux 2 autres.

```{r echo=FALSE, fig.height=8, fig.width=14}
par(mfrow=c(2,2))
detrend_sncf = Traffic_SNCF - trend_sncf
plot(as.ts(trend_sncf),ylim=c(1500,4000),col="red", main="Tendance")
plot(as.ts(detrend_sncf), main="Série sans la tendance")


m_sncf = t(matrix(data = detrend_sncf, nrow = 12))
seasonal_sncf = colMeans(m_sncf, na.rm = T)
plot(as.ts(rep(seasonal_sncf,12)), main="Série sans la saisonnalité")
#par(mfrow=c(2,1))
random_sncf = Traffic_SNCF - trend_sncf - seasonal_sncf
plot(as.ts(random_sncf), main="Le bruit restant")
```
\pagebreak

* Decomposition des séries temporelles avec la fonction *decompose* de R

On va décomposer la série temporelles en utilisant la fonction décompose de R de façon à avoir une idée générale de la tendance (trend) saisonalité et bruit. On remarque que les graphiques obtenus sont très similaire avec ceux obtenus précédement.

```{r echo=FALSE}
decompose_sncf <- decompose(Traffic_SNCF)
plot(decompose_sncf)#, col = "red")
```

La tendance est nette, on a aussi une saisonnalité qui semble marquée. Par contre le bruit présente une structure.
La modélisation doit être améliorée.
La fonction decompose en  modèle multiplicatif n'apporte pas d'amélioration au niveau de la distribution des résidus, qui semble toujours dépendre du temps.

* Reconstitution de la série

A partir des différentes composantes calculées précédemment, on peut recontruire la série.

```{r echo=FALSE, fig.height=5, fig.width=14}
par(mfrow=c(1,2))
recomposed_sncf = trend_sncf+seasonal_sncf+random_sncf
plot(Traffic_SNCF,xlab='Temps',ylab="Evolution du traffic voyageurs",main="Reconstitution de la série avec modèle additif",)
points(trend_sncf,type='l',col=2)
points(recomposed_sncf,type='l',col='purple')
legend('topleft',c(expression(X[t]),expression(m[t]),expression(m[t]+s[t])),
col=c(1,2,'purple'),lty=1)

plot(Traffic_SNCF,xlab='Temps',ylab="Evolution du traffic voyageurs",main='decompose() avec modèle additif')
points(decompose_sncf$trend,type='l',col=2)
points(decompose_sncf$trend+decompose_sncf$seasonal,type='l',col='purple')
legend('topleft',c(expression(X[t]),expression(m[t]),expression(m[t]+s[t])),
col=c(1,2,'purple'),lty=1)
```

```{r echo=FALSE}

```

Pour évaluer la performance de prédiction, nous allons estimer les paramètres du modèle sur la série allant de janvier 1962 jusqu'à décembre 1979 et garder les observations de l'année 1980 pour les comparer avec les prévisions.

```{r echo=FALSE}
Traffic_SNCF.6379 <- window(Traffic_SNCF,start=1970,end=c(1979,12))
```


## Prévision par lissage exponentiel 

On obtient les différents lissages à partir de la fonction ets de R. 

Le lissage exponentiel simple (ANN) est obtenu à partir du paramètre model=ANN où :
La première lettre A de model="ANN" signifie que l'erreur est additive. 
La deuxième lettre concerne la tendance, N indique qu'il n'y en a pas.
La troisième lettre concerne la saisonnalitée, N indique qu'il n'y en a pas.

Dans le lissage exponentiel double model=AAN on considère une tendance additive.
Et pour le lissage exponentiel triple ou de  Holt-Winters on considére qu'il y a en plus une saisonnalité additive model=AAA

```{r echo=FALSE}
fitLED <- ets(Traffic_SNCF.6379,model="AAN")
fitHW  <- ets(Traffic_SNCF.6379,model="AAA")
fitLES <-ets(Traffic_SNCF.6379,model="ANN")
```

On peut comparer ces méthodes de lissage, en terme de critères AIC, AICc et BIC à partir du tableau suivant :

 Type de lissage Exponentiel |       AIC      |        AICc     |       BIC      | 
---------------------------- | -------------- | --------------- | -------------- |  
Lissage Simple (A,N,N)       | `r fitLES$aic` | `r fitLES$aicc` | `r fitLES$bic` | 
Lissage Double (A,A,N)       | `r fitLED$aic` | `r fitLED$aicc` | `r fitLED$bic` | 
Holt-Winters   (A,A,A)       | `r fitHW$aic`  | `r fitHW$aicc`  | `r fitHW$bic`  | 

Nous remarquons que le modele est trop basique dans notre cas pour predire a l'horizon 12 et que l'intervalle de confiance a 80%, bien que tres large, ne contient pas toutes les vraies valeurs de la serie. On peut utilser predict(fitLES,12) prediction a horizon 1 an.

On remarque que le lissage double n'apporte pas vraiment d'amélioration par raport au simple. Les critères AIC et BIC sont plus élevés dans le cas du lissage double par rapport au lissage simple. Le lissage exponentiel triple ou de Holt-Winters apporte une amélioration.

On peut considérer d'autres méthodes de lissage en jouant sur le caractères Additif/Multiplicatif des composantes.
On a vu précédemment, que la tendance était plutôt additive, on va donc fixer la tendance=A et faire varier les autres paramètres.

```{r echo=FALSE}
fitMAA <- ets(Traffic_SNCF.6379,model="MAA")
#fitAAM <- ets(Traffic_SNCF.6379,model="AAM")
fitMAM <- ets(Traffic_SNCF.6379,model="MAM")
```

Modèle   |       AIC      |        AICc     |        BIC     | 
-------- | -------------- | --------------- | -------------- |  
(M,A,A)  | `r fitMAA$aic` | `r fitMAA$aicc` | `r fitMAA$bic` | 
(M,A,M)  | `r fitMAM$aic` | `r fitMAM$aicc` | `r fitMAM$bic` | 

```{r echo=FALSE, fig.height=5, fig.width=14}
par(mfrow=c(1,2))
predLES = forecast(fitLES,h=12)
plot(predLES)
points(Traffic_SNCF,type='l',col='darkgreen',lwd=1)
legend('top',c("Valeurs observées","Prédictions"), col=c("darkgreen","blue"), lty=rep(1,2),lwd = rep(2,2))

predLED <- forecast(fitLED,h=12)
plot(predLED)
points(Traffic_SNCF,type='l',col='darkgreen',lwd=1)
legend('top',c("Valeurs observees","Predictions"),col=c("darkgreen","blue"),lty=rep(1,2),lwd = rep(2,2))
```

```{r echo=FALSE, fig.height=5, fig.width=14}
par(mfrow=c(1,2))
predHW <- forecast(fitHW,h=12)
plot(predHW)
points(Traffic_SNCF,type='l',col='darkgreen',lwd=1)
legend('top',c("Valeurs observees","Predictions"),col=c("darkgreen","blue"),lty=rep(1,2),lwd = rep(2,2))

predMAA <- forecast(fitMAA,h=12)
plot(predMAA)
points(Traffic_SNCF,type='l',col='darkgreen',lwd=1)
legend('top',c("Valeurs observees","Predictions"),col=c("darkgreen","blue"),lty=rep(1,2),lwd = rep(2,2))

```

* Procédure automatique - modèles ajustés par ets.

La fonction ets permet aussi un ajustement automatique du modéle, lorsqu'aucun modèle n'est spécifié. 
```{r echo=FALSE}
fit.ets <- ets(Traffic_SNCF.6379)
#fitAIC <- ets(Traffic_SNCF.6379,ic="aic")

#summary(fit.ets)
#summary(fitAIC)
```

Le modèle sélectionné est le modèle avec tendance additive et avec erreur et saisonnalité multiplicatives (M,A,M). C'est aussi ce modèle qui minimise le critère AIC, AICc et BIC. En effet, en spécifiant le critère à minimiser: AIC, AICc et BIC avec le paramètre ic="aic"/"aicc" ou bic" de la fonction ets, on obtient toujours le même modèle.

Modèle   |        AIC      |        AICc      |        BIC      | 
-------- | --------------- | ---------------- | --------------- |  
(M,A,M)  | `r fit.ets$aic` | `r fit.ets$aicc` | `r fit.ets$bic` | 

```{r echo=FALSE, fig.height=5, fig.width=8}
predfit.ets <- forecast(fit.ets,h=12)
plot(predfit.ets, main=" Prédiction à partir du modèle de lissage exponentiel obtenu : (M,A,M)")
points(Traffic_SNCF.6379,type='l',col='darkgreen',lwd=1)
legend('top',c("Valeurs observées","Prédictions"),col=c("darkgreen","blue"),lty=rep(1,2),lwd = rep(2,2))
```

## Modélisation
On cherche ici à modéliser la série par un processus stationnaire ARMA(p,q) ou bien SARMA(p,q).
Si besoin on cherchera à stationnariser la série en utilisant l'opérateur de différentiation. 
On obtiendra alors une modélisation à partir de processus ARIMA (p,d,q) ou SARIMA(p,d,q)

### Identification du modèle
La première étape est l'étude de la stationnarité du processus régissant la série. 
Pour identifier le modèle on commence par une étude de la stationarité en traçant le corrélogramme de la série, la valeur de $\rho_X(h)$ en fonction de h. On va voir que l'on observe une périodicité annuelle, lorsque h = 12 dans le cas ici de données mensuelles. Pour mettre en évidence ce phénomène, on trace le corrélogramme de la série et de la série différentiée.

* Corrélogramme de $X_t$ et de $(1-B)X_t$

```{r echo=FALSE, fig.height=4, fig.width=15}
par(mfrow=c(1,2))
#acf(Traffic_SNCF.6379,type ="covariance",lag.max=60)
acf(Traffic_SNCF.6379,type ="correlation",lag.max=60)
acf(diff(Traffic_SNCF.6379,difference=1), lag.max=60) 
```

La fonction d'autocorrélation estimée est positive. On remarque une périodicité de 1 (12 mois) (graphique de gauche).On peut essayer de différentier la série au moins une fois (graphique de droite). On remarque des autocorrélations importantes pour les valeurs de h de 1 période (année), tout les 12 mois. C'est aussi ce que l'on avait remarqué précedemment avec le lag plot.
On va donc appliquer l'opérateur $(1-B^{12})$ à la série précédente, transformée par diffrentiation :  $(1-B)X_t$. Et lon trace le corrélogramme associé.

```{r echo=FALSE, fig.height=4, fig.width=8}
#par(mfrow=c(1,2))
acf(diff(Traffic_SNCF.6379,lag=12,difference=1), lag.max=180) 
```
Le corrélogramme de la série obtenue par différentiation: $(1-B)(1-B^{12})X_t$ ne présente plus de fortes amplitudes pour les petites valeurs de h.
Ni pour h multiple de 12 comme c'était le cas pour la série brute.
On peut considérer que la série ainsi transformé est issue d'un processus stationnaire.
Il y a encore cependant encore d'assez fortes valeurs pour $\hat{\rho}(1)$ ce qui indique d'ajouter un terme dans la partie MA du modèle.

On peut regarder l'autocorrélation partielle pour avoir une idée du terme degrès q du terme moyenne mobile MA(q) du modèle. 

```{r echo=FALSE, fig.height=5, fig.width=10}
#par(mfrow=c(1,2))
pacf(diff(Traffic_SNCF.6379,lag=12,difference=1), lag.max=180) 
```

L'autocorrélation partielle suggère un terme d'ordre q=1 (12ème mois) soit un terme moyenne mobile du type : $(1-\theta_1 B)(1-\theta_2 B^{12})\epsilon_t)$ 

On obtient ainsi un modèle du type SARIMA(0,1,1)(0,1,1)

$(1-B)(1-B^{12})X_t = (1-\theta_1 B)(1-\theta_2 B^{12})\epsilon_t)$ où $E\epsilon_t=0$ et $V\epsilon_t=\sigma^2$

p176 

* Elimination de la tendance

```{r echo=FALSE, fig.height=5, fig.width=15}
par(mfrow=c(1,2))
diff_sncf<-diff(Traffic_SNCF.6379,lag=12,differences = 1)

plot(Traffic_SNCF.6379,main="Différentiation saisonnière - lag=12 et differences = 1")

trend.diff_sncf<-diff(diff(Traffic_SNCF.6379,lag=12,difference=1),lag=1,difference=1)
plot(trend.diff_sncf,main="Avec élimination de la tendance")
```

\pagebreak

* Validation du modèle obtenu par différentiation saisonnière

```{r echo=FALSE, message=FALSE, warning=FALSE}
tdf1<-adf.test(diff(Traffic_SNCF.6379,lag=12,difference=1))
#tdf2<-adf.test(diff(diff(Traffic_SNCF.6379,lag=12,difference=1),lag=1,difference=1))
```
On confirme cette hypothèse à l'aide d'un test de $Dickey-Fuller$ on obtient une p_value=`r tdf1$p.value`
On a donc réussit à amélioré la staionnarité de la série avec une différentiantion saisonnière. 

```{r echo=FALSE}
box<-Box.test(diff(Traffic_SNCF.6379,lag=12,difference=1),lag=20,type="Box-Pierce")
```

Et le test du Portmanteau ou test de blancheur sur R n'est quant à lui pas concluant et donne une p_value=`r box$p.value`

On va maintenant estimer plusieurs modèles SARIMA(p,1,q)(r,1,s) en faisant varier les paramètres p et q de 0 à 2 et la saisonnalité (r,1,s) de 0 à 1.


```{r echo=FALSE}
#m_trend.season<-diff(diff(Traffic_SNCF.6379,lag=12,difference=1),lag=1,difference=1)
m_trend.season<-diff(Traffic_SNCF.6379,lag=12,difference=1)
m_trend.season<-Traffic_SNCF.6379
s010_011=Arima(m_trend.season,order=c(0,1,0), seasonal=c(0,1,1))
s010_010=Arima(m_trend.season,order=c(0,1,0), seasonal=c(0,1,0))
s010_110=Arima(m_trend.season,order=c(0,1,0), seasonal=c(1,1,0))
s010_111=Arima(m_trend.season,order=c(0,1,0), seasonal=c(1,1,1))

s011_011=Arima(m_trend.season,order=c(0,1,1), seasonal=c(0,0,1))
s011_010=Arima(m_trend.season,order=c(0,1,1), seasonal=c(0,1,0))
s011_110=Arima(m_trend.season,order=c(0,1,1), seasonal=c(1,1,0))
s011_111=Arima(m_trend.season,order=c(0,1,1), seasonal=c(1,1,1))

s110_011=Arima(m_trend.season,order=c(1,1,0), seasonal=c(0,1,1))
s110_010=Arima(m_trend.season,order=c(1,1,0), seasonal=c(0,1,0))
s110_110=Arima(m_trend.season,order=c(1,1,0), seasonal=c(1,1,0))
s110_111=Arima(m_trend.season,order=c(1,1,0), seasonal=c(1,1,1))

s111_011=Arima(m_trend.season,order=c(1,1,1), seasonal=c(0,1,1))
s111_010=Arima(m_trend.season,order=c(1,1,1), seasonal=c(0,1,0))
s111_110=Arima(m_trend.season,order=c(1,1,1), seasonal=c(1,1,0))
s111_111=Arima(m_trend.season,order=c(1,1,1), seasonal=c(1,1,1))

s112_011=Arima(m_trend.season,order=c(1,1,2), seasonal=c(0,1,1))
s112_010=Arima(m_trend.season,order=c(1,1,2), seasonal=c(0,1,0))
s112_110=Arima(m_trend.season,order=c(1,1,2), seasonal=c(1,1,0))
s112_111=Arima(m_trend.season,order=c(1,1,2), seasonal=c(1,1,1))

s211_011=Arima(m_trend.season,order=c(2,1,1), seasonal=c(0,1,1))
s211_010=Arima(m_trend.season,order=c(2,1,1), seasonal=c(0,1,0))
s211_110=Arima(m_trend.season,order=c(2,1,1), seasonal=c(1,1,0))
s211_111=Arima(m_trend.season,order=c(2,1,1), seasonal=c(1,1,1))
```

On peut utiliser une approche empirique et regarder le critère AIC AICc et BIC des différents modèle obtenues on prendra celui qui minimise ces critères. 

SARIMA  |        AIC       |        AICc       |       BIC       | 
------- | ---------------- | ----------------- | --------------- |
010_011 | `r s010_011$aic` | `r s010_011$aicc` |`r s010_011$bic` |
010_010 | `r s010_010$aic` | `r s010_010$aicc` |`r s010_010$bic` |
010_110 | `r s010_110$aic` | `r s010_110$aicc` |`r s010_110$bic` |
010_111 | `r s010_111$aic` | `r s010_111$aicc` |`r s010_111$bic` |
011_011 | `r s011_011$aic` | `r s011_011$aicc` |`r s011_011$bic` |
011_010 | `r s011_010$aic` | `r s011_010$aicc` |`r s011_010$bic` |
011_110 | `r s011_110$aic` | `r s011_110$aicc` |`r s011_110$bic` |
011_111 | `r s011_111$aic` | `r s011_111$aicc` |`r s011_111$bic` |
110_011 | `r s110_011$aic` | `r s110_011$aicc` |`r s110_011$bic` |
110_010 | `r s110_010$aic` | `r s110_010$aicc` |`r s110_010$bic` |
110_110 | `r s110_110$aic` | `r s110_110$aicc` |`r s110_110$bic` |
110_111 | `r s110_111$aic` | `r s110_111$aicc` |`r s110_111$bic` |
111_011 | `r s111_011$aic` | `r s111_011$aicc` |`r s111_011$bic` |
111_010 | `r s111_010$aic` | `r s111_010$aicc` |`r s111_010$bic` |
111_110 | `r s111_110$aic` | `r s111_110$aicc` |`r s111_110$bic` |
111_111 | `r s111_111$aic` | `r s111_111$aicc` |`r s111_111$bic` |
112_011 | `r s112_011$aic` | `r s112_011$aicc` |`r s112_011$bic` |
112_010 | `r s112_010$aic` | `r s112_010$aicc` |`r s112_010$bic` |
112_110 | `r s112_110$aic` | `r s112_110$aicc` |`r s112_110$bic` |
112_111 | `r s112_111$aic` | `r s112_111$aicc` |`r s112_111$bic` |
211_011 | `r s211_011$aic` | `r s211_011$aicc` |`r s211_011$bic` |
211_010 | `r s211_010$aic` | `r s211_010$aicc` |`r s211_010$bic` |
211_110 | `r s211_110$aic` | `r s211_110$aicc` |`r s211_110$bic` |
211_111 | `r s211_111$aic` | `r s211_111$aicc` |`r s211_111$bic` |

En terme de minimisation des critères AIC, AICc et BIC les 3 meilleurs modèles sont les modèles :
SARIMA(1,1,2)(0,1,1), SARIMA(2,1,1)(1,1,1), SARIMA(1,1,1)(1,1,1) et le modèle initial SARIMA(0,1,1)(0,1,1)

```{r echo=FALSE}

```

### Validation des modèles SARIMA obtenus

Avant de paser à la prédiction, on va maintenant valider ou invalider les modèles obtenus.

* Test de Box-Pierce 

```{r echo=FALSE}
b112_011<-Box.test(s112_011$residuals,lag=20)
b211_011<-Box.test(s211_011$residuals,lag=20)
b111_111<-Box.test(s111_111$residuals,lag=20)
b111_011<-Box.test(s111_011$residuals,lag=20)
b011_011<-Box.test(s011_011$residuals,lag=20)

```
Le test de blancheur des résidus rejette nettement le modèles SARIMA(0,1,1)(0,1,1) avec une p-value < 2.2e-16.
Pour les autres 3 modèles SARIMA(2,1,1)(0,1,1), SARIMA(1,1,2)(0,1,1), SARIMA(1,1,1)(1,1,1) et SARIMA(1,1,1)(0,1,1) on accepte la blancheur des résidus comme le montre le tableau ci-dessous.

SARIMA   |      p-value         |   
-------  | -------------------- |
011_011  | `r b011_011$p.value` |
111_011  | `r b111_011$p.value` |
112_011  | `r b112_011$p.value` |
211_011  | `r b211_011$p.value` |
111_111  | `r b111_111$p.value` |

* ACF et PACF des résidus

```{r echo=FALSE, fig.height=4, fig.width=15}
par(mfrow=c(1,3))
acf(s111_011$residuals,lag=120)
pacf(s111_011$residuals,lag=120)
plot(s111_011$residuals,  main="Résidus SARIMA(1,1,1)(0,1,1)")
```

```{r echo=FALSE, fig.height=4, fig.width=15}
par(mfrow=c(1,3))
acf(s112_011$residuals,lag=120)
pacf(s112_011$residuals,lag=120)
plot(s112_011$residuals, main="Résidus SARIMA(1,1,2)(0,1,1)")
```

```{r echo=FALSE, fig.height=4, fig.width=15}
par(mfrow=c(1,3))
acf(s211_011$residuals,lag=120)
pacf(s211_011$residuals,lag=120)
plot(s211_011$residuals, main="Résidus SARIMA(2,1,1)(0,1,1)")
```

```{r echo=FALSE, fig.height=4, fig.width=15}
par(mfrow=c(1,3))
acf(s111_111$residuals,lag=120)
pacf(s111_111$residuals,lag=120)
plot(s111_111$residuals, main="Résidus SARIMA(1,1,1)(1,1,1)")
```


* Statistiques 

Qualité de l'estimation des coefficients du modèle.

SARIMA(1,1,1)(0,1,1) :
```{r echo=FALSE}
t_stat(s111_011)
```
SARIMA(2,1,1)(0,1,1) :
```{r echo=FALSE}
t_stat(s211_011)
```
SARIMA(1,1,2)(0,1,1) :
```{r echo=FALSE}
t_stat(s112_011)
```
SARIMA(1,1,1)(1,1,1) :
```{r echo=FALSE}
t_stat(s111_111)
```

* Corrélations

SARIMA(2,1,1)(1,1,1) :
```{r echo=FALSE}
cor.arma(s111_011)
```
SARIMA(2,1,1)(1,1,1) :
```{r echo=FALSE}
cor.arma(s211_011)
```
SARIMA(1,1,2)(0,1,1) :
```{r echo=FALSE}
cor.arma(s112_011)
```
SARIMA(1,1,1)(1,1,1) :
```{r echo=FALSE}
cor.arma(s111_111)
```

```{r echo=FALSE}

```


## Modélisation automatique avec R

On estime ici le modèle de manière automatique en utilisant la fonction $auto.arima$ de R.

```{r echo=FALSE}
autoarima111_011<-auto.arima(Traffic_SNCF.6379)
autoarima111_011
```

* Validation du modèle obtenu :

```{r echo=FALSE}
t_stat(autoarima111_011)
```

```{r echo=FALSE}
cor.arma(autoarima111_011)
```

```{r echo=FALSE}
bt<-Box.test(autoarima111_011$residuals,lag=20)
```

Le test de blancheur des résidus ou test Box-Pierce est accepté avec la p-value :  `r bt$p.value`

```{r echo=FALSE, fig.height=5, fig.width=15}
par(mfrow=c(1,3))
acf(autoarima111_011$residuals,lag=120)
pacf(autoarima111_011$residuals,lag=120)
plot(autoarima111_011$residuals, col="blue", main="Résidus SARIMA(1,1,1)(0,1,1)")
```

```{r echo=FALSE}

```

## Prévisions et comparaison des modèles obtenus

```{r echo=FALSE}
predauto_111_011=forecast(autoarima111_011,12)
predSARIMA_011_011=forecast(s011_011,12)
predSARIMA_111_111=forecast(s111_111,12)
predSARIMA_112_011=forecast(s112_011,12)
predSARIMA_211_011=forecast(s211_011,12)

```

* Prédictions SARIMA(1,1,1)(0,1,1)

```{r echo=FALSE}
predauto_111_011
```

```{r echo=FALSE}
# Prédictions SARIMA(1,1,2)(0,1,1)
#predSARIMA_112_011
```

* Comparaison entre les différents modèles SARIMA

```{r echo=FALSE}

plot(Traffic_SNCF,col="darkgreen",lwd=2,ylab="Nombre de Passagers",xlab="Temps",lty=2, xlim=c(1980,1981),ylim=range(c(Traffic_SNCF,predauto_111_011$lower,predauto_111_011$upper,predSARIMA_111_111$lower,predSARIMA_111_111$upper)))
points(predSARIMA_111_111$mean,col="yellow",lwd=1,type='l',lty=1)
points(predSARIMA_112_011$mean,col="blue",lwd=1,type='l',lty=2)
points(predSARIMA_211_011$mean,col="black",lwd=1,type='l',lty=3)
points(predauto_111_011$mean,col="red",lwd=1,type='l',lty=4)

legend("topleft",
       c("Vraies valeurs","SARIMA_011-111", "SARIMA_112-011", "SARIMA_211-011","SARIMA_111-011","SARIMA_111-011"),
       col=c("darkgreen", "yellow","blue","black","red"),
       lty=c(2,1,2,3,4),lwd=1,cex=0.7)
```

Les modèles sont quasiment confondus, excepté le SARIMA(0,1,1)(1,1,1) qui est très légèrement décalé.
Ils suivent plutôt bien la courbe des données des vraies valeurs.

* Comparaison entre SARIMA(1,1,1)(0,1,1) et lissage exponentiel

```{r echo=FALSE}
fitHW=ets(Traffic_SNCF.6379,model="MMM")
predHW=forecast(fitHW,h=12)
```

```{r echo=FALSE, fig.height=5, fig.width=15}
par(mfrow=c(1,2))
plot(Traffic_SNCF,col="darkgreen",lwd=1,ylab="Nombre de Passagers",xlab="Temps", xlim=c(1962,1982),ylim=range(c(Traffic_SNCF,predauto_111_011$lower,predauto_111_011$upper,predHW$lower,predHW$upper)))
points(predauto_111_011$mean,col="red",lwd=2,type='l')

plot(Traffic_SNCF,col="darkgreen",lwd=1,ylab="Nombre de Passagers",xlab="Temps", xlim=c(1979,1981),ylim=range(c(Traffic_SNCF,predauto_111_011$lower,predauto_111_011$upper,predHW$lower,predHW$upper)))
points(predauto_111_011$mean,col="red",lwd=2,type='l')
points(predauto_111_011$lower[,2],col="red",type='l',lty=2)
points(predauto_111_011$upper[,2],col="red",type='l',lty=2)
points(predHW$mean,col="blue",lwd=2,type='l')
points(predHW$lower[,2],col="blue",type='l',lty=3)
points(predHW$upper[,2],col="blue",type='l',lty=3)
legend("topleft",c("Vraies valeurs","SARIMA","Liss.exp."),col=c("darkgreen","red","blue"),lty=c(rep(1,3),2),lwd=c(rep(2,3),1),cex=0.7)
```

Remarque : la stabilisation de la variance en utilisant la fonction log n'apporte pas l'atténuation souhaité, et est sans effet ici.


```{r eval=FALSE, echo=FALSE}
m_LogSncfSARIMA=auto.arima(log(Traffic_SNCF.6379))
```

```{r eval=FALSE, echo=FALSE}
t_stat(m_LogSncfSARIMA)
```

```{r eval=FALSE, echo=FALSE}
cor.arma(m_LogSncfSARIMA)
```

```{r eval=FALSE, echo=FALSE}
Box.test(m_LogSncfSARIMA$residuals,lag=20)

```

```{r echo=FALSE}

```



\pagebreak

# Partie II - Tentative de modélisation d'un indice boursier de type action à l'aide de processus ARIMA

## Introduction
On cherche dans cette partie à modéliser par des processus de type ARIMA ou assimilé (SARIMA) l'évolution du prix d'indice boursier de type acion.
En fait un poretefeuille d'actions, ou indice type CAC40, DAX, Eurostoxx, SP500...
Pour cette première étude on va se baser sur l'indice CAC40.
A parir de la modélisation (présupposée possible) obtenu on va chercher à prévoir l'évolution de l'indice en question, à horizon 3 mois, 6 mois voire 1 an.

Notre but est double :

* La définition de stress test de type action : A partir de la modélisation obtenue, et de l'intervalle de confiance sous jacent, on va chercher à déterminer une valeur de choc absolue à la hausse et à la baisse.
Cette méthodologie de définition d'un choc absolue associé à un niveau de confiance devrait nous aider à définir un scénario économique plausible (avec un certain seuil de confiance) à horizon 3mois, 6mois et 1an.
Ainsi cette modélisation devrait pouvoir nos guider dans la détermination de stress test de type action. 
Pour ête complet quant à la définition de stress test de type financier, il faudrait parvenir à définir une méthodologie équivalente pour les produits de types taux ou courbes de taux d'intérêt.
Ce dernier cas est plus complexe dans la mesure où on cherche à modéliser une surface et les séries temporelles ne sont peut ête pas appropriées.
Plus précisemment on cherche à modéliser un faisceau de courbes aléatoires qui dépendent les unes des autres. Le mécanisme de dépendance étant en parti connu, ou plutôt des modèles éxistent.

* Elaboration d'un portefeuille simplifié : Une fois les principaux indices modélisé, on va chercher à décomposer nos portefeuilles sur ces indices et ainsi constituer un portefeuille simplifié.
Ce portefeuille simplifié serait la base d'un indice benchmark du portefeuille étudié.

Dans un premier temps on va étudier la série temporelle associée à l'évoultion du prix de l'indice étudié le CAC40 : représenttion graphique, saisonnalité, tendance, stationarité...
Pour entrer dans le cadre d'un modèle ARMA(p,q), on va dans un premier temps, étudier la stationarité de notre série. Et la rendre stationnaire le cas échéant.
A partir de là on cherchera à déterminer les paramètres p et q du processus auto régressif AR(p) et moyenne mobile MA(q) sous jacent à parir des graphiques ACF et PACF.
Enfin on ajustera les coefficient pour obtenir notre modèle. On terminera l'étude en validant le modèle: blancheur des résidus, ndépendance, normalité. 
On pourra alors après validation l'utiliser pour nos prédictions.

## Lecture des données et premières analyses

Les données ont été récupérées sur le site Yahoo Finance. Ticker "^FCHI" pour les données de l'indice CAC40.
On considère un jeu de données quotidienne et un autre mensuel. Avec dans les 2 cas un historique de Janvier 1998 à Janvier 2020.
A partir de cet historique de 22 ans on va construire différentes séries de profondeur d'historique différente.
Après avoir annalysé ces séries on essaiera de construire un modèle de type ARIMA pour chacune d'elles.

```{r d1_summary}
dataCAC40_raw_d <-read.table("Daily_Data_CAC40_1997-2019.csv", sep=",", dec=".",header=T, na.strings = "null")
dataCAC40_raw_m <-read.table("Mounthly_Data_CAC40_1997-2019.csv", sep=",", dec=".",header=T, na.strings = "null")
```

### Traitement des données 

Dans le cas des données journalières, il y a des données manquantes. On va les supprimer.
La variable Date est aussi connvertit en structure date.
```{r echo=FALSE}
summary(dataCAC40_raw_d)
```

```{r echo=FALSE}
dataCAC40_d<-dataCAC40_raw_d[which(dataCAC40_raw_d$Open != "NA"),]
#dataCAC40_d<-dataCAC40_raw
#dataCAC40_d[is.na(dataCAC40)] <- 0

FrameCAC40_d <- as.data.frame(dataCAC40_d)
FrameCAC40_d[['Date']] <- as.Date(FrameCAC40_d[['Date']], format='%Y-%m-%d')  
FrameCAC40_d[,2] <- as.numeric(as.character(FrameCAC40_d[,2]))
FrameCAC40_d[,3] <- as.numeric(as.character(FrameCAC40_d[,3]))
FrameCAC40_d[,4] <- as.numeric(as.character(FrameCAC40_d[,4]))
FrameCAC40_d[,5] <- as.numeric(as.character(FrameCAC40_d[,5]))
FrameCAC40_d[,6] <- as.numeric(as.character(FrameCAC40_d[,6]))

head(FrameCAC40_d)
#summary(FrameCAC40_d)
```

Dans le cas des données mensuelles ont n'a pas de problème de données manquantes.

```{r include=FALSE}
summary(dataCAC40_raw_m)
```

```{r echo=FALSE}
dataCAC40_m<-dataCAC40_raw_m[which(dataCAC40_raw_m$Open != "NA"),]
FrameCAC40_m <- as.data.frame(dataCAC40_m)
FrameCAC40_m[['Date']] <- as.Date(FrameCAC40_m[['Date']], format='%Y-%m-%d')  
FrameCAC40_m[,2] <- as.numeric(as.character(FrameCAC40_m[,2]))
FrameCAC40_m[,3] <- as.numeric(as.character(FrameCAC40_m[,3]))
FrameCAC40_m[,4] <- as.numeric(as.character(FrameCAC40_m[,4]))
FrameCAC40_m[,5] <- as.numeric(as.character(FrameCAC40_m[,5]))
FrameCAC40_m[,6] <- as.numeric(as.character(FrameCAC40_m[,6]))
#summary(FrameCAC40_m)
#head(FrameCAC40_m)
```

### conversion des données en objet *time series*
Ici on convertit les données en objet R ts (time series)
Dans le cas des données journalières on utilise pour le parmaètre de fréquence (nb jours dans l'année) la valeur 256
Ce qui correspond au nombre de jours par an (jours ouvrès sans les jours de fermeture) que l'on obtient une fois les NA supprimés.(On remarque que cette valeur de fréquence influe la vitesse de traitement lors de l'appel de la fonction auto.arima)

```{r echo=FALSE}
val<-5 #Close
freq<-256

tsCAC40_1998_Open_d<- FrameCAC40_d[FrameCAC40_d[,1]> as.Date("1997-12-31"),]
tsCAC40_1998_Open_d=ts(as.vector(tsCAC40_1998_Open_d[,val]),start=c(1998,1),frequency=freq)

FrameCAC40_2002_d <- FrameCAC40_d[FrameCAC40_d[,1]> as.Date("2001-12-31"),]
tsCAC40_2002_Open_d=ts(as.vector(FrameCAC40_2002_d[,val]),start=c(2002,1),frequency=freq)

FrameCAC40_2008_d <- FrameCAC40_d[FrameCAC40_d[,1]> as.Date("2007-12-31"),]
tsCAC40_2008_Open_d=ts(as.vector(FrameCAC40_2008_d[,val]),start=c(2008,1),frequency=freq)

FrameCAC40_2014_d <- FrameCAC40_d[FrameCAC40_d[,1]> as.Date("2013-12-31"),]
tsCAC40_2014_Open_d=ts(as.vector(FrameCAC40_2014_d[,val]),start=c(2014,1),frequency=freq)
```
```{r echo=FALSE}
tsCAC40_1998_Open_m<- FrameCAC40_m[FrameCAC40_m[,1]> as.Date("1997-12-31"),]
tsCAC40_1998_Open_m=ts(as.vector(FrameCAC40_m[,val]),start=c(1998,1),frequency=12)

FrameCAC40_2002_m <- FrameCAC40_m[FrameCAC40_m[,1]> as.Date("2001-12-31"),]
tsCAC40_2002_Open_m=ts(as.vector(FrameCAC40_2002_m[,val]),start=c(2002,1),frequency=12)

FrameCAC40_2008_m <- FrameCAC40_m[FrameCAC40_m[,1]> as.Date("2007-12-31"),]
tsCAC40_2008_Open_m=ts(as.vector(FrameCAC40_2008_m[,val]),start=c(2008,1),frequency=12)

FrameCAC40_2014_m <- FrameCAC40_m[FrameCAC40_m[,1]> as.Date("2013-12-31"),]
tsCAC40_2014_Open_m=ts(as.vector(FrameCAC40_2014_m[,val]),start=c(2014,1),frequency=12)
```

## Analyse des séries temporelles obtenues 
Comme déja énnoncé on va étudier plusieurs profondeur d'historique.

* Toute la série de janvier 1998 à janvier 2020 soit 22 années de profondeur d'historique.
* A partir de Janvier 2002 jusqu'à janvier 2020 soit 18 années de profondeur d'historique.
* A partir de Janvier 2008 jusqu'à janvier 2020 soit 12 années de profondeur d'historique.
* A partir de Janvier 2014 jusqu'à janvier 2020 soit 5 années de profondeur d'historique.
Et on considére 2 jeux de données, avec une fréquence quotidienne et mensuelle.

### Graphique des séries temporelles - valeur observée Prix à la fermeture (Close)

On a 4 séries temporelles possibles en fonction du choix de la quantité observée (High, Low, Open, Close, Volume).
On va s'intéresser à la valeur à la fermeture pour la cotation de l'indice CAC40 (Close).

```{r echo=FALSE, fig.height=8, fig.width=15}
par(mfrow=c(2,2))
plot(tsCAC40_1998_Open_d, xlab="Time",ylab="Open",main="Time serie - CAC40 Daily - 1998/2020")
plot(tsCAC40_2002_Open_d, xlab="Time",ylab="Open",main="Time serie - CAC40 Daily - 2002/2020")
plot(tsCAC40_1998_Open_m,xlab="Time",ylab="Open",main="Time serie - CAC40 Monthly - 1998/2020")
plot(tsCAC40_2002_Open_m,xlab="Time",ylab="Open",main="Time serie - CAC40 Daily - 2002/2020")
```

```{r echo=FALSE, fig.height=8, fig.width=15}
par(mfrow=c(2,2))
plot(tsCAC40_2008_Open_d,xlab="Time",ylab="Open",main="Time serie - CAC40 - 2008/2020")
plot(tsCAC40_2014_Open_d,xlab="Time",ylab="Open",main="Time serie - CAC40 - 20142/2020")
plot(tsCAC40_2008_Open_m,xlab="Time",ylab="Open",main="Time serie - CAC40 - 2008/2020")
plot(tsCAC40_2014_Open_m,xlab="Time",ylab="Open",main="Time serie - CAC40 - 20142/2020")
```
Dans le cas des données mensuelles On retrouve biensûr la forme globale de la série mais moins bruitée.
\pagebreak

### Représentations graphiques : month-plot et lag-plot

Si le diagramme retardée suggére une corrélation entre les deux séries, on dit que la série présente une autocorrélation d'ordre k.Ce diagramme permet de comprendre la dépendance de la série par rapport à son passée. Il donne une vision locale de la série, si y a une corrélation entre la série a un instant et la série 1, 2... instants avant.

```{r echo=FALSE, fig.height=3, fig.width=6}
monthplot(tsCAC40_2014_Open_m)
```
```{r echo=FALSE, fig.height=4, fig.width=6}
lag.plot(tsCAC40_2014_Open_m,lags=12,layout=c(3,4),do.lines=FALSE)
```
\pagebreak

### Etude de la stationarité
La stationnarité est la stationnarité du processus au sens faible.
Un tel processus doit avoir les propriétés suivantes : La moyenne et la variance ne varient pas au cours du temps et le processus n a pas de tendance.
Pour vérifier ces hypothèses, on s'appuiera sur une analyse des graphique d'autocorrélation ACF et d'autocorrélation partielle PACF ainsi que sur le test de $Dickey-Fuller$.

* Fonction d'autocorrélation ACF et PACF

```{r echo=FALSE, fig.height=5, fig.width=15}
par(mfrow=c(1,2))

#acf(tsCAC40_1998_Open_d, lag.max=60)    
#pacf(tsCAC40_1998_Open_d, lag.max=60)     
#
##acf(tsCAC40_2002_Open_d, lag.max=60)       
#pacf(tsCAC40_2002_Open_d, lag.max=60)           

#acf(tsCAC40_2008_Open_d, lag.max=60)          
#pacf(tsCAC40_2008_Open_d, lag.max=60)          

acf(tsCAC40_2014_Open_d, lag.max=60) 
pacf(tsCAC40_2014_Open_d, lag.max=60)  

```

On constate que les variables sont liées entre elles, i.e. les données ne semblent pas être stationnaires. 
```{r echo=FALSE, warning=FALSE}
#adf.test(tsCAC40_1998_Open_d)
#adf.test(tsCAC40_2002_Open_d)
#adf.test(tsCAC40_2008_Open_d)
t2014d<-adf.test(tsCAC40_2014_Open_d)
```

On confirme cette hypothèse à l'aide d'un test de $Dickey-Fuller$ on p_value=`r t2014d$p.value`.
```{r echo=FALSE, fig.height=8, fig.width=15}
par(mfrow=c(2,4))
acf(tsCAC40_1998_Open_m, lag.max=60)           
pacf(tsCAC40_1998_Open_m, lag.max=60)     

acf(tsCAC40_2002_Open_m, lag.max=60)       
pacf(tsCAC40_2002_Open_m, lag.max=60)           

acf(tsCAC40_2008_Open_m, lag.max=60)          
pacf(tsCAC40_2008_Open_m, lag.max=60)          

acf(tsCAC40_2014_Open_m, lag.max=60)            
pacf(tsCAC40_2014_Open_m, lag.max=60)         

```

Là aussi on constate que les variables sont liées entre elles, i.e. les données ne semblent pas être stationnaires. 
On confirme cette hypothèse à l'aide d'un test de $Dickey-Fuller$.

```{r echo=FALSE, message=FALSE, warning=FALSE}
t1998<-adf.test(tsCAC40_1998_Open_m)
t2002<-adf.test(tsCAC40_2002_Open_m)
t2008<-adf.test(tsCAC40_2008_Open_m)
t2014<-adf.test(tsCAC40_2014_Open_m)
```

série   |     Dickey-Fuller    |    Lag order       | p-value           | 
------- | ---------------------| ------------------ | ----------------- |
1998    | `r t1998$statistic`  |`r t1998$parameter` | `r t1998$p.value` | 
2002    | `r t2002$statistic`  |`r t2002$parameter` | `r t2002$p.value` |
2008    | `r t2008$statistic`  |`r t2008$parameter` | `r t2008$p.value` |
2014    | `r t2014$statistic`  |`r t2014$parameter` | `r t2014$p.value` |

La p-valeur de ce test est importante et confirme donc que les données ne sont pas stationnaires.
Il y a une cependant exception pour la série 2008.

### Decomposition des séries temporelles :
Ici on va décomposer la série temporelles en utilisant la fonction décompose de R de façon à avoir une idée générale de la tendance (trend) saisonalité et bruit.

```{r echo=FALSE}
decompose_1998_d <- decompose(tsCAC40_1998_Open_d)
#plot(decompose_1998_d)#, col = "red")

decompose_1998_m <- decompose(tsCAC40_1998_Open_m)
#plot(decompose_1998_m)#, col = "red")

decompose_2002_d <- decompose(tsCAC40_2002_Open_d)
#plot(decompose_2002_d)#, col = "red")

decompose_2002_m <- decompose(tsCAC40_2002_Open_m)
#plot(decompose_2002_m)#, col = "red")

decompose_2008_d <- decompose(tsCAC40_2008_Open_d)
#plot(decompose_2008_d)#, col = "red")

decompose_2008_m <- decompose(tsCAC40_2008_Open_m)
#plot(decompose_2008_m)#, col = "red")

decompose_2014_d <- decompose(tsCAC40_2014_Open_d)
plot(decompose_2014_d)#, col = "red")

decompose_2014_m <- decompose(tsCAC40_2014_Open_m)
#plot(decompose_2014_m)#, col = "red")
```

On retrouve les formes générales mais mon bruitées.La saisonnalité ne semble pas très nette.

On va essayer de rendre stationnaire nos séries. C'est un prérequis pour pouvoir effectuer une modilisation de type ARMA
En utilisant la différentiation on va essayer de se ramener à un processus ARMA.Ainsi on va essayer de modéliser l'évolution du prix de l'indice CAC4O par un processus ARIMA.
On commence donc par différentier les séries. Le facteur utilsé est de 1.
\pagebreak

## Détermination des modèles ARIMA

Les procssus ARIMA sont des processus non stationnaire.  
Un processus $X_t$ t Z est un processus ARIMA(p,d,q) si $\Delta^dX$ est un processus ARMA(p,q).

Les processus ARMA(p,q) font parti d'une famille très large des processus stationnaires.
Ces processus sont composés des processus auto-régressifs AR(p) et de moyennes mobiles ("moving average") MA(q).
Un processus ARMA est la combinaison des processus autorégressifs et moyennes mobiles.

On cherche dans un premeir temps à se ramener à un processus sationnaire en utilisant la différentiation. 
Si l'on est bien dans le cadre d'un modèle ARIMA, après l'opération de différentiation on se ramènera à l'étude d'un processus ARMA(p,q). 

### Stationarisation des processus par differentiation des séries 
Pour tenter de rendre la série stationnaire, on applique la méthode de différentiation. On utilise la function R diff.
En paramètre on passe un facteur de 1 pour la différence et 0 pour la saisonnalité.
On retrouve l'idée de la transformation Log-return $R_t$ des prix $X_t$ où $R_t=Log(X_t/X_{t-1})$ qui est classique en finance.

* Séries obtenues par differentiation pour les 2 jeux de données quotidien et mensuel à partir de 1998 et 2002

```{r echo=FALSE, fig.height=7, fig.width=13}
par(mfrow=c(2,2))
diff_1998_d<-diff(log(tsCAC40_1998_Open_d),differences = 1)
plot(diff_1998_d, main="Différentiation - Série journalière depuis 1998")#,col="red")

diff_2002_d<-diff(log(tsCAC40_2002_Open_d),differences = 1)
plot(diff_2002_d, main="Différentiation - Série journalière depuis 2002")#,col="red")

diff_1998_m<-diff(log(tsCAC40_1998_Open_m),differences = 1)
plot(diff_1998_m, main="Différentiation - Série mensuelle depuis 1998")

diff_2002_m<-diff(log(tsCAC40_2002_Open_m),differences = 1)
plot(diff_2002_m, main="Différentiation - Série mensuelle depuis 2002")

```

Au sens de la stationnarité faible, les séries semblent bien stationnaire.
On retrouve bien une moyenne nulle et constante dans le temps.
Ainsi qu'une variance constante bien que cet aspect soit moins évident.
On affaibliera cetre dernière hypothèse loes de l'étude des modèles GARCH au dernier paragraphe.

* Séries obtenues par differentiation pour les 2 jeux de données quotidien et mensuel à partir de 2008 et 2014

Les séries différenciées Yt = Xt − Xt−1 ont l'allure suivantes

```{r echo=FALSE, fig.height=7, fig.width=13}
par(mfrow=c(2,2))

diff_2008_d<-diff(log(tsCAC40_2008_Open_d),differences = 1)
plot(diff_2008_d, main="Différentiation - Série journalière depuis 2008")#,col="red")

diff_2014_d<-diff(log(tsCAC40_2014_Open_d),differences = 1)
plot(diff_2014_d, main="Différentiation - Série journalière depuis 2014")#,col="red")

diff_2008_m<-diff(log(tsCAC40_2008_Open_m),differences = 1)
plot(diff_2008_m, main="Différentiation - Série mensuelle depuis 2008")

diff_2014_m<-diff(log(tsCAC40_2014_Open_m),differences = 1)
plot(diff_2014_m, main="Différentiation - Série mensuelle depuis 2014")

```

Les chorélogrames des séries différentiés n'ont pas de fortes valeurs.

```{r echo=FALSE, fig.height=7, fig.width=12}
par(mfrow=c(2,2))

acf(diff_2008_d, lag.max=60)
pacf(diff_2008_d, lag.max=60)
acf(diff_2014_d, lag.max=60)
pacf(diff_2014_d, lag.max=60)
```

```{r echo=FALSE, fig.height=7, fig.width=12}
par(mfrow=c(2,2))

acf(diff_2008_m, lag.max=60)
pacf(diff_2008_m, lag.max=60)
acf(diff_2014_m, lag.max=60)
pacf(diff_2014_m, lag.max=60)
```

L'hypothèse de stationnarité du processus ainsi transformé étant acceptable, on peut envisager une modélisation ARIMA.
Compte tenu de l’allure des autocorrélogrammes de Yt, nous pouvons penser modéliser la série Xt par un processus ARMA (p, q).

On confirme cette impression avec différents tests de stationnarité.

* Test ADF - Augmented Dickey-Fuller Test (Robuste à l’autocorrélation)

```{r echo=FALSE, message=FALSE, warning=FALSE}
t1998d<-adf.test(diff_1998_d)
t2014d<-adf.test(diff_2014_d)
t2008d<-adf.test(diff_2008_d)
t2002d<-adf.test(diff_2002_d)

t1998m<-adf.test(diff_1998_m)
t2002m<-adf.test(diff_2002_m)
t2008m<-adf.test(diff_2008_m)
t2014m<-adf.test(diff_2014_m)
```

série   |     Dickey-Fulle r    |    Lag order        | p-value            | 
------- | ----------------------| ------------------- | ------------------ |
1998 j  | `r t1998d$statistic`  |`r t1998d$parameter` | `r t1998d$p.value` | 
2002 j  | `r t2002d$statistic`  |`r t2002d$parameter` | `r t2002d$p.value` |
2008 j  | `r t2008d$statistic`  |`r t2008d$parameter` | `r t2008d$p.value` |
2014 j  | `r t2014d$statistic`  |`r t2014d$parameter` | `r t2014d$p.value` |
1998 m  | `r t1998m$statistic`  |`r t1998m$parameter` | `r t1998m$p.value` | 
2002 m  | `r t2002m$statistic`  |`r t2002m$parameter` | `r t2002m$p.value` |
2008 m  | `r t2008m$statistic`  |`r t2008m$parameter` | `r t2008m$p.value` |
2014 m  | `r t2014m$statistic`  |`r t2014m$parameter` | `r t2014m$p.value` |


* Test PP - Phillips-Perron Unit Root Test (Robuste à l’hétéroscédasticité)

```{r echo=FALSE, message=FALSE, warning=FALSE}
t1998d<- pp.test(diff_1998_d)
t2014d<- pp.test(diff_2014_d)
t2008d<- pp.test(diff_2008_d)
t2002d<- pp.test(diff_2002_d)

t1998m<- pp.test(diff_1998_m)
t2002m<- pp.test(diff_2002_m)
t2008m<- pp.test(diff_2008_m)
t2014m<- pp.test(diff_2014_m)
```

série   | Dickey-Fuller Z(alpha)    | Truncation Lag order | p-value            | 
------- | --------------------------| -------------------- | ------------------ |
1998 j  | `r t1998d$statistic`      |`r t1998d$parameter`  | `r t1998d$p.value` | 
2002 j  | `r t2002d$statistic`      |`r t2002d$parameter`  | `r t2002d$p.value` |
2008 j  | `r t2008d$statistic`      |`r t2008d$parameter`  | `r t2008d$p.value` |
2014 j  | `r t2014d$statistic`      |`r t2014d$parameter`  | `r t2014d$p.value` |
1998 m  | `r t1998m$statistic`      |`r t1998m$parameter`  | `r t1998m$p.value` | 
2002 m  | `r t2002m$statistic`      |`r t2002m$parameter`  | `r t2002m$p.value` |
2008 m  | `r t2008m$statistic`      |`r t2008m$parameter`  | `r t2008m$p.value` |
2014 m  | `r t2014m$statistic`      |`r t2014m$parameter`  | `r t2014m$p.value` |

*  Test de KPSS

```{r echo=FALSE, message=FALSE, warning=FALSE}
t1998d<-kpss.test(diff_1998_d)
t2014d<-kpss.test(diff_2014_d)
t2008d<-kpss.test(diff_2008_d)
t2002d<-kpss.test(diff_2002_d)

t1998m<-kpss.test(diff_1998_m)
t2002m<-kpss.test(diff_2002_m)
t2008m<-kpss.test(diff_2008_m)
t2014m<-kpss.test(diff_2014_m)
```

série   |        KPSS Level     | Truncation Lag order | p-value            | 
------- | ----------------------| -------------------- | ------------------ |
1998 j  | `r t1998d$statistic`  |`r t1998d$parameter`  | `r t1998d$p.value` | 
2002 j  | `r t2002d$statistic`  |`r t2002d$parameter`  | `r t2002d$p.value` |
2008 j  | `r t2008d$statistic`  |`r t2008d$parameter`  | `r t2008d$p.value` |
2014 j  | `r t2014d$statistic`  |`r t2014d$parameter`  | `r t2014d$p.value` |
1998 m  | `r t1998m$statistic`  |`r t1998m$parameter`  | `r t1998m$p.value` | 
2002 m  | `r t2002m$statistic`  |`r t2002m$parameter`  | `r t2002m$p.value` |
2008 m  | `r t2008m$statistic`  |`r t2008m$parameter`  | `r t2008m$p.value` |
2014 m  | `r t2014m$statistic`  |`r t2014m$parameter`  | `r t2014m$p.value` |

Ces tests confirment la stationnarité de la série différentiée (difference=1).
A titre comparatif, la série Zt obtenue en différenciant 2 fois donne des résultats ne semblant pas significativement différents. Aussi, différencier 1 fois suffit pour obtenir un modèle stationnaire.

* Test d’autocorrélation :

Le test de Box-Pierce permet d’identifier les processus de bruit blanc (i.e. les processus aléatoires de moyenne nulle, de variance constante et non autocorrélés). Cette statistique permet de tester cov (εt, εt−h) = 0 pour tout h, soit ρ (h) = 0 pour tout h.

```{r echo=FALSE}
s1998d<-Box.test(diff_1998_d, lag = 10, type = "Box-Pierce")  
s2002d<-Box.test(diff_2002_d, lag = 10, type = "Box-Pierce") 
s2008d<-Box.test(diff_2008_d, lag = 10, type = "Box-Pierce")  
s2014d<-Box.test(diff_2014_d, lag = 10, type = "Box-Pierce")  

s1998<-Box.test(diff_1998_m, lag = 10, type = "Box-Pierce")  
s2002<-Box.test(diff_2002_m, lag = 10, type = "Box-Pierce") 
s2008<-Box.test(diff_2008_m, lag = 10, type = "Box-Pierce")  
s2014<-Box.test(diff_2014_m, lag = 10, type = "Box-Pierce")    
```

Pour les données quotidienne on ne rejette pas l’hypothèse que les accroissements du CAC40 est un bruit blanc.
A contrario pour les données mensuelles.

série   |     p-value        |
------- | ------------------ | 
1998    | `r s1998d$p.value` | 
2002    | `r s2002d$p.value` |
2008    | `r s2008d$p.value` |
2014    | `r s2014d$p.value` |
1998    | `r s1998$p.value`  | 
2002    | `r s2008$p.value`  |
2008    | `r s2008$p.value`  |
2014    | `r s2014$p.value`  |

If p-value < 0.05: You can reject the null hypothesis assuming a 5% chance of making a mistake. So you can assume that your values are showing dependence on each other.

If p-value > 0.05: You don't have enough statistical evidence to reject the null hypothesis. So you can not assume that your values are dependent. This could mean that your values are dependent anyway or it can mean that your values are independent. But you are not proving any specific possibility, what your test actually said is that you can not assert the dependence of the values, neither can you assert the independence of the values.

f the p value is greater than 0.05 then the residuals are independent which we want for the model to be correct. If you simulate a white noise time series using the code below and use the same test for it then the p value will be greater than 0.05.


* Test de normalité de Pearson 

```{r echo=FALSE}
s1998d<-pearson.test(diff_1998_d)  
s2002d<-pearson.test(diff_2002_d) 
s2008d<-pearson.test(diff_2008_d)  
s2014d<-pearson.test(diff_2014_d)  

s1998<-pearson.test(diff_1998_m)  
s2002<-pearson.test(diff_2002_m) 
s2008<-pearson.test(diff_2008_m)  
s2014<-pearson.test(diff_2014_m)    
```

série   |     p-value        |
------- | ------------------ | 
1998    | `r s1998d$p.value` | 
2002    | `r s2002d$p.value` |
2008    | `r s2008d$p.value` |
2014    | `r s2014d$p.value` |
1998    | `r s1998$p.value`  | 
2002    | `r s2008$p.value`  |
2008    | `r s2008$p.value`  |
2014    | `r s2014$p.value`  |

Les faibles p-values du test nous indique que l'hypothèse de normalité est rejetée pour les séries différentiées portant sur les données quotidiennes. mais est au contraire accepté en ce qui concerne les données menuselles.

Pour les données mensuelles, le CAC40 suit une marche aléatoire ce qui se concorde avec la théorie de l’effécience des marchés, 

Dans le cas des données quotidienne les accroissements ne sont pas normaux avec des régimes sur la variance (on constate des périodes calmes et d’autres agitées), ceci peut se résoudre de deux manières : i) utilisation des distributions avec des queues épaisses (Student, GED,...) ii) utilisation de l’approche d’Engel (1982) en modélisant les accroissement par un modèle ARCH (modèles Auto Régressifs Conditionnellement Hétéroscédastiques).

On a deux comportement différents en ce qui concerne les données mensuelles et quotidiennes.

On va passer maintenant à la détermination des paramètres p et q du mopdèle ARIMA(p,1,q).
A partir de maintenant on ne va   

### Détermination des paramètres p et q 

L'estimation de p et de q se fait simplement en lisant le graphe des fonctions d'auto-corrélation et d'auto-corrélation partielle. 
Le graphe de la fonction d'auto-corrélation nous fournit la valeur de q. Le graphe de la fonction d'autocorrélation partielle nous donne la valeur de p. 
On peut alors essayer d'améliorer le modèle en prenant des valeurs de p et q plus petites que les valeurs obtenues précédemment, en utilisant notamment les critères d'AIC ou de BIC.

* Etudes des corrélogrammes et autocorrélations partiels (acf et pacf)

```{r echo=FALSE, fig.height=4, fig.width=12}
par(mfrow=c(1,2))

acf(diff_2014_m, lag.max=60)
pacf(diff_2014_m, lag.max=60)
```

La fonction d'autocorrélation (ACF) d'un AR(p) montre une décroissance exponentielle avec ou sans oscillations vers 0.
La fonction d'autocorrélation partielle (PACF) d'un AR(p) est nulle à partir de l'ordre p+1.

L'ACF d'un processus MA(q) est nulle à partir de l'ordre q + 1.
si une ACF empirique semble nulle à partir d'un certain ordre q + 1, on peut penser qu'il s'agit de l'ACF d'une série MA(q).


Cependant pour certains processus, ni la fonction d'autocorrélation, ni la fonction d'autocorrélation partielle ne possèdent de point de rupture. Dans de tels cas, il faut construire un modele mixte.

La PACF d'un processus qui a une composante moyenne mobile a une décroissance exponentielle. Ainsi la PACF d'un ARMA(p,q), q > 0 présente une décroissance exponentielle.

Ici la PACF ne décroît pas exponentiellement, et rien de très net ne ressort des différents graphiques.


```{r echo=FALSE}
EACF=eacf(tsCAC40_2014_Open_m,7,7)
EACF
```
```{r echo=FALSE}
EACF=eacf(diff_2014_m,7,7)
EACF
```

```{r echo=FALSE}
 armaselect(tsCAC40_2014_Open_m,nbmod=5)
```

```{r echo=FALSE}
ARMA.SELECTION=armasubsets(tsCAC40_2014_Open_m,nar=14,nma=14,ar.method='ols')
 plot(ARMA.SELECTION)

```



### Méthode automatique de calibration d'un modèles ARIMA

```{r arima_2014, echo=FALSE}
#♥arima_2014_d <- auto.arima(tsCAC40_2014_Open_d, max.p = 3, max.q = 3, max.d = 3)
arima_2014_m <- auto.arima(tsCAC40_2014_Open_m, trace=TRUE, max.p = 7, max.q = 7, max.d = 3)
#arima_2014_d
arima_2014_m
```
Pour les 2 jeux de données à partir de 2008 on obtient un SARIMA(0,1,0)(1,0,0) dans le cas des données quotidiennes
et un SARIMA(1,1,0)(2,0,2) pour les données mensuelles.

Pour les 2 jeux de données à partir de 2014 on obtient un ARIMA(0,1,0) soit une marche aléatoire.

On va s'intéresser maintenant aux données journalières depuis 2014. Les autres séries quotidiennes n'ayant pas permis d'obtenir ici des modèles compatibles avec le test de blancheur des résidus. Le test étant rejetté de manière très significative.

```{r echo=FALSE}
arima_010=Arima(tsCAC40_2014_Open_m,order=c(0,1,0))
arima_110=Arima(tsCAC40_2014_Open_m,order=c(1,1,0))
arima_011=Arima(tsCAC40_2014_Open_m,order=c(0,1,1))
arima_111=Arima(tsCAC40_2014_Open_m,order=c(1,1,1))
arima_012=Arima(tsCAC40_2014_Open_m,order=c(0,1,2))
arima_112=Arima(tsCAC40_2014_Open_m,order=c(1,1,2))
arima_210=Arima(tsCAC40_2014_Open_m,order=c(2,1,0))
arima_211=Arima(tsCAC40_2014_Open_m,order=c(2,1,1))
arima_212=Arima(tsCAC40_2014_Open_m,order=c(2,1,2))

arima_310=Arima(tsCAC40_2014_Open_m,order=c(3,1,0))
arima_311=Arima(tsCAC40_2014_Open_m,order=c(3,1,1))
arima_312=Arima(tsCAC40_2014_Open_m,order=c(3,1,2))

arima_410=Arima(tsCAC40_2014_Open_m,order=c(4,1,0))
arima_411=Arima(tsCAC40_2014_Open_m,order=c(4,1,1))
arima_412=Arima(tsCAC40_2014_Open_m,order=c(4,1,2))
```

On peut utiliser une approche empirique et regarder le critère AIC AICc et BIC des différents modèle obtenues on prendra celui qui minimise ces critères. 

* Voici le résultat obtenu pour la série 2014 quotidienne :

ARIMA   |        AIC        |        AICc       |       BIC       | 
------- | ----------------- | ------------------| --------------- |
010     | `r arima_010$aic` | `r arima_010$aic` |`r arima_010$aic`|
110     | `r arima_110$aic` | `r arima_110$aic` |`r arima_110$aic`|
011     | `r arima_011$aic` | `r arima_011$aic` |`r arima_011$aic`|
111     | `r arima_111$aic` | `r arima_111$aic` |`r arima_111$aic`|
012     | `r arima_012$aic` | `r arima_012$aic` |`r arima_012$aic`|
112     | `r arima_112$aic` | `r arima_112$aic` |`r arima_112$aic`|
210     | `r arima_210$aic` | `r arima_210$aic` |`r arima_210$aic`|
211     | `r arima_211$aic` | `r arima_211$aic` |`r arima_211$aic`|
212     | `r arima_212$aic` | `r arima_212$aic` |`r arima_212$aic`|

On remarque que selon ce critère plusieurs modéles sont très proches : ARIMA(0,1,0), ARIMA(0,1,1), ARIMA(0,1,2), ARIMA(1,1,1), ARIMA(1,1,2), ARIMA(2,1,1),  ARIMA(2,1,2)

```{r echo=FALSE}
arima_010=Arima(tsCAC40_2014_Open_m,difference=1,order=c(0,1,0))
arima_110=Arima(tsCAC40_2014_Open_m,difference=1,order=c(1,1,0))
arima_011=Arima(diff(tsCAC40_2014_Open_m,difference=1),order=c(0,1,1))
arima_111=Arima(diff(tsCAC40_2014_Open_m,difference=1),order=c(1,1,1))
arima_012=Arima(diff(tsCAC40_2014_Open_m,difference=1),order=c(0,1,2))
arima_112=Arima(diff(tsCAC40_2014_Open_m,difference=1),order=c(1,1,2))
arima_210=Arima(diff(tsCAC40_2014_Open_m,difference=1),order=c(2,1,0))
arima_211=Arima(diff(tsCAC40_2014_Open_m,difference=1),order=c(2,1,1))
arima_212=Arima(diff(tsCAC40_2014_Open_m,difference=1),order=c(2,1,2))
```

## Validation des modèles obtenus

### Blancheur des résidus

Le test de Box-Pierce permet d’identifier les processus de bruit blanc (i.e. les processus aléatoires de moyenne nulle, de variance constante et non autocorrélés).

```{r echo=FALSE, warning=FALSE}
#Box.test(arima_1998_d$residuals,lag=20,type="Box-Pierce")
#Box.test(arima_2008_d$residuals,lag=20,type="Box-Pierce")
t2014d <- Box.test(arima_2014_d$residuals,lag=20,type="Box-Pierce")
```

Dans ce cas aussi le test de blancheur des résidus n'est pas vraiment significatif.

Par contre pour le cas des données mensuelles le test est concluant dans tous les cas.

```{r echo=FALSE, warning=FALSE}
t1998  <- Box.test(arima_1998_m$residuals,lag=20,type="Box-Pierce")
t1998b <- Box.test(arima_1998_m$residuals,lag=20,type="Ljung-Box")
t2008  <- Box.test(arima_2008_m$residuals,lag=20,type="Box-Pierce")
t2008b <- Box.test(arima_2008_m$residuals,lag=20,type="Ljung-Box")
t2014  <- Box.test(arima_2014_m$residuals,lag=20,type="Box-Pierce")
t2014b <- Box.test(arima_2014_m$residuals,lag=20,type="Ljung-Box")
```

*Test de Box-Pierce*

série   |     X-squared        |       df           | p-value           | 
------- | ---------------------| ------------------ | ----------------- |
1998    | `r t1998$statistic`  |`r t1998$parameter` | `r t1998$p.value` | 
2008    | `r t2008$statistic`  |`r t2008$parameter` | `r t2008$p.value` |
2014    | `r t2014$statistic`  |`r t2014$parameter` | `r t2014$p.value` |

*Test de Ljung-Box*

série   |     X-squared         |       df            |      p-value       | 
------- | ----------------------| ------------------- | ------------------ |
1998    | `r t1998b$statistic`  |`r t1998b$parameter` | `r t1998b$p.value` | 
2008    | `r t2008b$statistic`  |`r t2008b$parameter` | `r t2008b$p.value` |
2014    | `r t2014b$statistic`  |`r t2014b$parameter` | `r t2014b$p.value` |

Dans le cas des modèles sur données mensuelles le test de blancheur des résidus accepte le modèle, et ce dans tous les cas.
Pour les données mensuelles, le test renvoi une grande p-value et donc les résidus ne sont pas corrélés.
Dans le cas des données quotidienne au contraire le modèle n'est pas validé la p-value la plus importante est obtenu pour les données 2014: `r t2014d$p.value`.
La profondeur de l'historique et la forme de la courbe associé semble aussi jouer un rôle.

```{r echo=FALSE, warning=FALSE}
#t_stat(arima_1998_d)
#cor.arma(arima_1998_d)
#t_stat(arima_2008_d)
#cor.arma(arima_2008_d)
#t_stat(arima_2014_d)
#cor.arma(arima_2014_d)

```

### Graphiques de résidus obtenus à partir des différents modèles
```{r echo=FALSE,  fig.height=5, fig.width=15, warning=FALSE}
par(mfrow=c(1,2))
#plot.ts(arima_1998_m$residuals) 
#plot.ts(arima_2008_d$residuals)    
 
#plot.ts(arima_2008_m$residuals, col="blue")  
plot.ts(arima_2014_d$residuals) 
plot.ts(arima_2014_m$residuals, col="blue")    

```

Dans le cas des données quotidiennes on a une variance non constante.
On va utiliser les modèles GARCH comme alternatve. On verra qu'ils sont mieux adaptées à la modélisation des séries financières.
On abandonne pour le momment l'étude des données quotidienne dans le cadre d'une modélisation ARIMA.

### Normalité des résidus

On regarde les tests classiques de normalités dans le cadre des données mensuelles.

```{r echo=FALSE}
#plot.ts(arima_1998_m$residuals) 
#shapiro.test(arima_2008_d$residuals)    
s2014d<-shapiro.test(arima_2014_d$residuals) 
s1998<-shapiro.test(arima_1998_m$residuals)  
#s2002<-shapiro.test(arima_2002_m$residuals) 
s2008<-shapiro.test(arima_2008_m$residuals)  
s2014<-shapiro.test(arima_2014_m$residuals)    
```

*Test de `r s2014$method`*

série   |     p-value       |
------- | ------------------| 
1998    | `r s1998$p.value` | 
2008    | `r s2008$p.value` |
2014    | `r s2014$p.value` |


```{r echo=FALSE}

#plot.ts(arima_1998_m$residuals) 
#shapiro.test(arima_2008_d$residuals)    
s2014d<-lillie.test(arima_2014_d$residuals) 
s1998<-lillie.test(arima_1998_m$residuals)  
#s2002<-shapiro.test(arima_2002_m$residuals) 
s2008<-lillie.test(arima_2008_m$residuals)  
s2014<-lillie.test(arima_2014_m$residuals)    
```

*Test de `r s2014$method`*

série   |     p-value       |
------- | ------------------| 
1998    | `r s1998$p.value` | 
2008    | `r s2008$p.value` |
2014    | `r s2014$p.value` |

Les données suivent bien une loi de Gauss pour les données d'historiqueà partir de 2008 et de manière plus nette pour l'historique à patir de 2014. 


```{r echo=FALSE, warning=FALSE}
#ggplot(data.frame(residuals = forecasts_1998_d$residuals), aes(residuals)) + geom_histogram(bins = 50, aes(y = ..density..), col = "red", fill = "red", alpha = 0.3) + geom_density()

#ggplot(data.frame(residuals = arima_2008_d$residuals), aes(residuals)) + geom_histogram(bins = 50, aes(y = ..density..), col = "red", fill = "red", alpha = 0.3) + geom_density()

##ggplot(data.frame(residuals = arima_2014_d$residuals), aes(residuals)) + geom_histogram(bins = 50, aes(y = ..density..), col = "red", fill = "red", alpha = 0.3) + geom_density()

```

```{r echo=FALSE, warning=FALSE}
#ggplot(data.frame(residuals = arima_1998_m$residuals), aes(residuals)) + geom_histogram(bins = 50, aes(y = ..density..), col = "red", fill = "red", alpha = 0.3) + geom_density()

#ggplot(data.frame(residuals = arima_2008_m$residuals), aes(residuals)) + geom_histogram(bins = 50, aes(y = ..density..), col = "red", fill = "red", alpha = 0.3) + geom_density()

#ggplot(data.frame(residuals = arima_2014_m$residuals), aes(residuals)) + geom_histogram(bins = 50, aes(y = ..density..), col = "red", fill = "red", alpha = 0.3) + geom_density()

```

### Prévisions à partir des modèles obtenus
Ces prévisions seront utilisées pour nous permettre de déterminer les valeurs possibles prise par l'indice CAC40 à horizon 1 mois, 2 mois, 6 mois
On souhaite utiliser l'intervalle de confiance obtenu pour nos aider à déterminer un scénario économique possible sur les actionS.
Vue que l'on est dans le cadre de stress tests on cherche à déterminser un choc absolue plausible et non pas obtenir la valueur du CAC à horizon.

```{r echo=FALSE, fig.height=5, fig.width=15}
#help("forecast")
par(mfrow=c(1,2))
#forecasts_1998_d <- forecast(arima_1998_d, h = 60)
#plot(forecasts_1998_d)

#forecasts_2008_d <- forecast(arima_2008_d, h = 60)
#plot(forecasts_2008_d)

forecasts_2014_d <- forecast(arima_2014_d, h = 60)
plot(forecasts_2014_d)

#forecasts_2008_m <- forecast(arima_2008_m, h = 2)
#plot(forecasts_2008_m)

forecasts_2014_m <- forecast(arima_2014_m, h = 2)
plot(forecasts_2014_m)

```

Les erreurs de prédictions obtenues semble suivre une normale centré et de variance assez constante.
Le modèle ARIMA semble être adpaté pour la prédiction.

The forecast errors seem to be normally distributed with mean zero and constant variance, the ARIMA model does seem to provide an adequate predictive model
Here we looked at how to best fit ARIMA model to univariate time series.
Next thing that I'll work on is Multivariate Time Series Forecasting using neural net.

Cependant on remarque que la


7.5 Choix d’un modèle
7.5.1 Critère de pouvoir prédicitf
Comme nous le verrons par la suite, dans un modèle ARMA, l’erreur de prévision à
horizon 1 dépend de la variance du résidu. On peut alors choisir le modèle conduisant à
la plus petite erreur de prévision. Plusieurs indicateurs sont alors possibles :
(i) la variance du résidu σ
2
, ou la somme des carrés des résidus SCR
(ii) le coefficient de détermination R2
, correspondant à une normalisation de la variance
(iii) le coeffivient de détermination modifié R
2
(iv) la statistique de Fisher (comme dans le cas du modèle linéaire)
Le but est alors de minimiser (i), ou de maximiser (ii),(iii) ou (iv).


\pagebreak

## Alternative au modèle de type ARIMA, les modèles GARCH

Modèles ARCH - volatilité stochastique ARCH (autorégressifs conditionnellement hétéroscédastiques).
la volatilité conditionelle d’une série (Yt) n’a aucune raison d’être constante.

Ces modèles prenne en compte l'hétérocédasticité. Ils sont mieux adapotés aux séries financières.

Les séries financières comme ont a pu le voir, ne sont pas stationaire. Et on observe une tendance locale B1 p227.

Comme ont la fait dans le caxs de la modélisation ARIMA on transforme la série originelle par différentiation.
Pour obtenir une série stationnaire. 
Ici on va considérer comme c'est souvent le cas en finance le log-return. C'est à dire la quantité déduite du prix $X_t$ de la manière suivante :
Log-return $R_t$ des prix $X_t$ où $R_t=Log(X_t/X_{t-1})$.
Cette appproche est bien adaptée au cadre de la théorie de Black-Scholes.
On pourra se reporter au Document D3 page 

D'après D3 page 96 :
Au regard de l’autocorrélogramme partiel du log return, une modélisation à l’aide d’un modèle GARCH(1, 1) semblerait possible. 
En effet, l’autocorrélogramme et l’autocorrélogramme partiel sont significativement nuls à partir des premiers retards (i.e. p = q = 1)
Dans notre cas vu que l'indice et la période diffère.

* Obtention de la série des log return

```{r warning=FALSE}
cac40 <- diff(log(tsCAC40_2014_Open_d))
```

* Graphique de la série obtenue

```{r echo=FALSE}
plot(cac40,col='blue',main='Log Rendement du CAC 40 de 2014 à 2020',xlab='Temps',ylab='Rendement')
```

```{r echo=FALSE, warning=FALSE}

```


```{r echo=FALSE, fig.height=12, fig.width=12, warning=FALSE}
par(mfrow=c(2,1))
acf(cac40)
pacf(cac40)
```


```{r}

```



```{r echo=FALSE, warning=FALSE}
cac.garch <- garch(cac40)  # Fit a GARCH(1,1) to cac returns
```


```{r}
summary(cac.garch)  
```

### Graphique des résidus

```{r echo=FALSE, warning=FALSE}

plot(cac.garch$residuals, col="blue") 

```

Les résidus obtenus sont plus conforme à un bruit blanc.

### Prévision obtenus à partir du modèle GARCH(1,1)

```{r warning=FALSE}


```

```{r warning=FALSE}


```


## Références

Books :

* (B1) Statistics of finantial Markets (J. Franke, W.K. Härdle, C. M. Hafner)
* (B2) Series-Temporelles-avec-R-methodes et cas (Y. Aragon)

Documents:

* (D1) Modèles GARCH et à volatilité stochastique (Christian. Francq)
* (D2) Time Series Analysis with ARIMA – ARCH/GARCH model in R (L-Stern Group - Ly Pham)
* (D3) Séries Temporelles et test d'adéquation d'un modèle GARCH(1,1) (Y. Djabrane)
* (D4) Rapport ISFA - Les Momentums et leur application dans le cadre des marchés boursiers (M. Adil Rahimi)

Blog/Internet: 

* (I1) https://tradingninja.com/2017/03/sp-500-exponential-garch-volatility-model-using-r/
* (I2) https://tradingninja.com/2016/01/financial-time-series-modelling-using-arima-plus-garch-models/


